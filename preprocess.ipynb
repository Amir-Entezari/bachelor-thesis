{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/speech6/bagher/aentezari/project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.venv', '.git', 'dataset', 'src']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# drive_path = '/content/drive/MyDrive'  # Adjust path if using google drive\n",
    "drive_path = os.getcwd()  # Adjust path if using google drive\n",
    "if os.path.exists(drive_path):\n",
    "  folder_names = [f for f in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, f))]\n",
    "  print(folder_names)\n",
    "else:\n",
    "  print(\"Drive path does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'dataset/derivatives/embeddings' is 1063393452 bytes (1014.13 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for file in filenames:\n",
    "            file_path = os.path.join(dirpath, file)\n",
    "            # Skip if the file is a symbolic link\n",
    "            if not os.path.islink(file_path):\n",
    "                total_size += os.path.getsize(file_path)\n",
    "    return total_size\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'dataset/derivatives/embeddings'\n",
    "size_in_bytes = get_directory_size(directory_path)\n",
    "size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "print(f\"Size of '{directory_path}' is {size_in_bytes} bytes ({size_in_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this code if you have the preprocessed dataset\n",
    "from scipy.signal import resample\n",
    "\n",
    "dataset_dir = 'dataset/'\n",
    "rootdir = dataset_dir + 'derivatives'\n",
    "participants_file = dataset_dir + 'participants.tsv'\n",
    "output_dir = dataset_dir + 'derivatives/processed_dataset'\n",
    "\n",
    "\n",
    "chunk_size = 15000  # 30 seconds of data at 500 Hz\n",
    "overlap = 7500   # 15 seconds overlap (7500 samples)\n",
    "new_sampling_rate = 100  # Target sampling rate\n",
    "original_sampling_rate = 500  # Original sampling rate\n",
    "\n",
    "# Load participants information\n",
    "participants_df = pd.read_csv(participants_file, sep='\\t')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Process each subject\n",
    "subjects = os.listdir(rootdir)\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(rootdir, subject)\n",
    "\n",
    "    if not os.path.isdir(subject_dir):\n",
    "        continue\n",
    "\n",
    "    subject_dir += '/eeg'\n",
    "\n",
    "    # Match participant_id in participants.tsv\n",
    "    participant_row = participants_df[participants_df['participant_id'] == subject]\n",
    "    if participant_row.empty:\n",
    "        print(f\"Warning: No matching entry in participants.tsv for {subject}\")\n",
    "        continue\n",
    "\n",
    "    # Extract labels\n",
    "    labels = {\n",
    "        \"MMSE\": int(participant_row[\"MMSE\"]),\n",
    "        \"Group\": participant_row[\"Group\"].values[0],\n",
    "        \"Age\": int(participant_row[\"Age\"]),\n",
    "        \"Gender\": participant_row[\"Gender\"].values[0]\n",
    "    }\n",
    "\n",
    "    subject_output_dir = os.path.join(output_dir, subject)\n",
    "    if not os.path.exists(subject_output_dir):\n",
    "        os.makedirs(subject_output_dir)\n",
    "\n",
    "    # Process each file in the subject's directory\n",
    "    for file_name in os.listdir(subject_dir):\n",
    "        if file_name.endswith('.set'):\n",
    "            file_path = os.path.join(subject_dir, file_name)\n",
    "\n",
    "            try:\n",
    "                # Load EEG data\n",
    "                raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
    "                data = raw.get_data()  # Get the raw EEG data as a numpy array\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Split data into 30-second chunks with 15-second overlap\n",
    "            num_samples = data.shape[1]\n",
    "            start = 0\n",
    "            chunk_index = 0\n",
    "            while start + chunk_size <= num_samples:\n",
    "                end = start + chunk_size\n",
    "                chunk_data = data[:, start:end]\n",
    "                # Downsample the chunk\n",
    "                resampled_chunk_data = resample(\n",
    "                    chunk_data,\n",
    "                    int(chunk_data.shape[-1] * new_sampling_rate / original_sampling_rate),\n",
    "                    axis=-1\n",
    "                )\n",
    "                # Create sample dictionary\n",
    "                sample = {\n",
    "                    \"data\": resampled_chunk_data,\n",
    "                    \"label\": labels['Group']\n",
    "                }\n",
    "\n",
    "                # Save chunk\n",
    "                output_file_name = file_name.replace('.set', f'_chunk_{chunk_index:03d}.pt')\n",
    "                output_file_path = os.path.join(subject_output_dir, output_file_name)\n",
    "                print(f'subject: {file_name} sample :{chunk_index}:start: {start} end: {end} start + chunk_size: {start + chunk_size }\\n Path: {output_file_path}')\n",
    "                torch.save(sample, output_file_path)\n",
    "                print(resampled_chunk_data.shape)\n",
    "\n",
    "                # Update indices\n",
    "                start += overlap\n",
    "                chunk_index += 1\n",
    "            # Handle the remaining data at the end\n",
    "            # if start < num_samples:\n",
    "            #     chunk_data = data[:, start:num_samples]\n",
    "\n",
    "            #     resampled_chunk_data = resample(\n",
    "            #         chunk_data,\n",
    "            #         int(chunk_data.shape[-1] * new_sampling_rate / original_sampling_rate),\n",
    "            #         axis=-1\n",
    "            #     )\n",
    "\n",
    "            #     sample = {\n",
    "            #         \"data\": resampled_chunk_data,\n",
    "            #         \"label\": labels['Group']\n",
    "            #     }\n",
    "\n",
    "            #     output_file_name = file_name.replace('.set', f'_chunk_{chunk_index:03d}.pt')\n",
    "            #     output_file_path = os.path.join(subject_output_dir, output_file_name)\n",
    "            #     torch.save(sample, output_file_path)\n",
    "\n",
    "            #     print(f'Subject: {file_name}, Final Sample: {chunk_index}, Start: {start}, End: {num_samples}, Saved at: {output_file_path}')\n",
    "\n",
    "print(\"Processing complete. Processed data saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File .set size: 23.23 MB\n",
      "(19, 299900)\n",
      "File .pt size: 66.02 MB\n"
     ]
    }
   ],
   "source": [
    "# data = torch.load('/content/drive/MyDrive/Colab Notebooks/ds004504/derivatives/sub-005/eeg/sub-005_task-eyesclosed_eeg.set')\n",
    "file_size = os.path.getsize('dataset/derivatives/sub-001/eeg/sub-001_task-eyesclosed_eeg.set')\n",
    "file_size_mb = file_size / (1024 ** 2)\n",
    "print(f\"File .set size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "raw = mne.io.read_raw_eeglab('dataset/derivatives/sub-001/eeg/sub-001_task-eyesclosed_eeg.set', preload=True)\n",
    "data = raw.get_data()\n",
    "print(data.shape)\n",
    "torch.save(data, 'test.pt')\n",
    "\n",
    "file_size = os.path.getsize('test.pt')\n",
    "file_size_mb = file_size / (1024 ** 2)\n",
    "print(f\"File .pt size: {file_size_mb:.2f} MB\")\n",
    "os.remove('test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
